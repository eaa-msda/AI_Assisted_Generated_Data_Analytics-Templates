{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z64DpUKCKVNV"
      },
      "outputs": [],
      "source": [
        "# Errol Ian Ave Acosta\n",
        "# Data Analysis | Google Colab\n",
        "# Grok 3 Free\n",
        "# February 16, 2025\n",
        "\n",
        "\"\"\"\n",
        "Additional Instructions:\n",
        "\n",
        "Replace all placeholder names (like 'column_name', 'numerical_feature', etc.) with the actual names from your dataset.\n",
        "If your data has different formats (e.g., JSON, Excel), you might need to use different loading functions (pd.read_json(), pd.read_excel()).\n",
        "Be cautious with operations like dropping outliers or filling missing data; these can bias your analysis if not done thoughtfully.\n",
        "For more complex analyses, you might want to look into time series analysis, more advanced statistical tests, or machine learning techniques not covered here.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "# Notes: Replace 'path/to/your/dataset.csv' with the actual path to your CSV file\n",
        "df = pd.read_csv('path/to/your/dataset.csv')\n",
        "\n",
        "# Initial Exploration\n",
        "# Notes: Basic data statistics and info\n",
        "print(df.info())  # Shows data types, non-null count, and memory usage\n",
        "print(df.describe())  # Summary statistics for numerical columns\n",
        "print(df.isnull().sum())  # Check for missing values\n",
        "\n",
        "# Data Cleaning\n",
        "# Notes: Handle missing values, adjust 'column_name' to your actual column\n",
        "# Example: Fill NaN values with the mean of the column\n",
        "df['column_name'] = df['column_name'].fillna(df['column_name'].mean())\n",
        "\n",
        "# Data Visualization\n",
        "# Notes: Visualize data to understand distributions and relationships\n",
        "\n",
        "# 1. Histogram for a numerical feature\n",
        "# Replace 'numerical_feature' with your column name\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['numerical_feature'], kde=True)\n",
        "plt.title('Histogram of Numerical Feature')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# 2. Bar plot for categorical data\n",
        "# Replace 'categorical_feature' with your column name\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=df, x='categorical_feature')\n",
        "plt.title('Count of Categories in Categorical Feature')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# 3. Box plot to check for outliers\n",
        "# Replace 'feature_for_outliers' with your column name\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=df['feature_for_outliers'])\n",
        "plt.title('Box Plot for Outlier Detection')\n",
        "plt.show()\n",
        "\n",
        "# Correlation Analysis\n",
        "# Notes: Understand how variables are related to each other\n",
        "correlation_matrix = df.corr()\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n",
        "\n",
        "# Data Manipulation\n",
        "# Notes: Performing some basic data operations\n",
        "\n",
        "# Example: Group by and aggregate\n",
        "# Replace 'group_by_column' and 'aggregate_column' with your column names\n",
        "grouped_data = df.groupby('group_by_column')['aggregate_column'].mean()\n",
        "print(grouped_data)\n",
        "\n",
        "# Example: Create a new feature\n",
        "# Replace 'feature1' and 'feature2' with your actual column names\n",
        "df['new_feature'] = df['feature1'] + df['feature2']\n",
        "\n",
        "# Outlier Detection\n",
        "# Notes: Remove outliers if necessary\n",
        "# Example: Using IQR for outlier detection on a single feature\n",
        "Q1 = df['feature_for_outliers'].quantile(0.25)\n",
        "Q3 = df['feature_for_outliers'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "df_cleaned = df[(df['feature_for_outliers'] >= lower_bound) & (df['feature_for_outliers'] <= upper_bound)]\n",
        "\n",
        "# Basic Statistical Analysis\n",
        "# Notes: Perform simple statistical tests\n",
        "# Example: T-test between two groups\n",
        "from scipy.stats import ttest_ind\n",
        "group1 = df[df['categorical_feature'] == 'Category1']['numerical_feature']\n",
        "group2 = df[df['categorical_feature'] == 'Category2']['numerical_feature']\n",
        "t_stat, p_val = ttest_ind(group1, group2)\n",
        "print(f\"T-statistic: {t_stat}, P-value: {p_val}\")\n",
        "\n",
        "# Save Cleaned Data\n",
        "# Notes: Save the processed data for future use\n",
        "# Replace 'path/to/save/cleaned_data.csv' with your desired save location\n",
        "df_cleaned.to_csv('path/to/save/cleaned_data.csv', index=False)\n",
        "\n",
        "# Final Notes:\n",
        "# - Remember to customize this script based on your dataset's specifics.\n",
        "# - Always verify that operations like filling NaNs or removing outliers make sense for your data.\n",
        "# - Consider data privacy and ethical implications when handling real data.\n",
        "# - This script provides a basic framework; real-world data analysis often requires more in-depth steps.\n"
      ]
    }
  ]
}